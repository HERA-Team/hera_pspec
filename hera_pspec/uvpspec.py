import numpy as np
from collections import OrderedDict as odict
import os, copy, shutil, operator, ast, fnmatch
from hera_pspec import conversions, noise, version, pspecbeam
from hera_pspec.parameter import PSpecParam
from pyuvdata import uvutils as uvutils
import h5py


class UVPSpec(object):
    """
    An object for storing power spectra generated by hera_pspec and a file-format
    for its data and meta-data.
    """
    def __init__(self):
        """
        An object for storing power spectra and its associated meta-data generated by hera_pspec.
        """
        # Summary attributes
        self._Ntimes = PSpecParam("Ntimes", description="Number of unique times.", expected_type=int)
        self._Nblpairts = PSpecParam("Nblpairts", description="Total number of baseline-pair times.", expected_type=int)
        self._Nblpairs = PSpecParam("Nblpairs", description='Total number of baseline-pairs.', expected_type=int)
        self._Nspwdlys = PSpecParam("Nspwdlys", description="Total number of delay bins across all sub-bands.", expected_type=int)
        self._Nspws = PSpecParam("Nspws", description="Number of spectral windows.", expected_type=int)
        self._Ndlys = PSpecParam("Ndlys", description="Total number of delay bins.", expected_type=int)
        self._Nfreqs = PSpecParam("Nfreqs", description="Total number of frequency bins in the original data.", expected_type=int)
        self._Npols = PSpecParam("Npols", description="Number of polarizations in the data.", expected_type=int)
        self._history = PSpecParam("history", description='The file history.', expected_type=str)

        # Data attributes
        desc = "Power spectrum data dictionary with spw integer as keys and values as complex ndarrays."
        self._data_array = PSpecParam("data_array", description=desc, expected_type=dict, form="(Nblpairts, Ndlys, Npols)")
        desc = "Weight dictionary for original two datasets. The second axis holds [dset1_wgts, dset2_wgts] in that order."
        self._wgt_array = PSpecParam("wgt_array", description=desc, expected_type=dict, form="(Nblpairts, Nfreqs, 2, Npols)")
        desc = "Integration time dictionary. This holds the average integration time [seconds] of each delay spectrum in the data. " \
               "This is not necessarily equal to the integration time of the visibility data: If data have been coherently averaged " \
               "(i.e. averaged before squaring), than this is the sum of each spectrum's integration time."
        self._integration_array = PSpecParam("integration_array", description=desc, expected_type=dict, form="(Nblpairts, Npols)")
        desc = "Nsample dictionary, if the pspectra have been incoherently averaged (i.e. averaged after squaring), this is " \
               "the effective number of samples in that average (float type). This is not the same as the pyuvdata.UVData nsample_array."
        self._nsample_array = PSpecParam("nsample_array", description=desc, expected_type=dict, form="(Nblpairts, Npols)")
        self._spw_array = PSpecParam("spw_array", description="Spw integer array.", form="(Nspwdlys,)")
        self._freq_array = PSpecParam("freq_array", description="Frequency array of the original data in Hz.", form="(Nspwdlys,)")
        self._dly_array = PSpecParam("dly_array", description="Delay array in seconds.", form="(Nspwdlys,)")
        desc = "Polarization integers of power spectra. Stokes 1:4 (I,Q,U,V); circular -1:-4 (RR,LL,RL,LR); linear -5:-8 (XX,YY,XY,YX)"
        self._pol_array = PSpecParam("pol_array", description=desc, form="(Npols,)")
        self._lst_1_array = PSpecParam("lst_1_array", description="LST array of the first bl in the bl-pair [radians].", form="(Nblpairts,)")
        self._lst_2_array = PSpecParam("lst_2_array", description="LST array of the second bl in the bl-pair [radians].", form="(Nblpairts,)")
        self._lst_avg_array = PSpecParam("lst_avg_array", description="Average of the lst_1_array and lst_2_array [radians].", form="(Nblpairts,)")
        self._time_1_array = PSpecParam("time_1_array", description="Time array of the first bl in the bl-pair [Julian Date].", form="(Nblpairts,)")
        self._time_1_array = PSpecParam("time_2_array", description="Time array of the second bl in the bl-pair [Julian Date].", form="(Nblpairts,)")
        self._time_avg_array = PSpecParam("time_avg_array", description="Average of the time_1_array and time_2_array [Julian Date].", form='(Nblparits,)')
        self._blpair_array = PSpecParam("blpair_array", description="Baseline-pair integer for all baseline-pair times.", form="(Nblpairts,)")

        # Baseline attributes
        self._Nbls = PSpecParam("Nbls", description="Number of unique baseline integers.", expected_type=int)
        self._bl_vecs = PSpecParam("bl_vecs", description="ndarray of baseline separation vectors in the ITRF frame [meters]. To get it in ENU frame see self.get_ENU_bl_vecs().", expected_type=np.ndarray, form="(Nbls,)")
        self._bl_array = PSpecParam("bl_array", description="All unique baseline (antenna-pair) integers.", expected_type=np.ndarray, form="(Nbls,)")

        # Misc Attributes
        self._channel_width = PSpecParam("channel_width", description="width of visibility frequency channels in Hz.", expected_type=float)
        self._telescope_location = PSpecParam("telescope_location", description="telescope location in ECEF frame [meters]. To get it in Lat/Lon/Alt see pyuvdata.utils.LatLonAlt_from_XYZ().", expected_type=np.ndarray)
        self._weighting = PSpecParam("weighting", description="Form of data weighting used when forming power spectra.", expected_type=str)
        self._norm = PSpecParam("norm", description="Normalization method adopted in OQE (M matrix).", expected_type=str)
        self._taper = PSpecParam("taper", description='Taper function applied to visibility data before FT."', expected_type=str)
        self._vis_units = PSpecParam("vis_units", description="Units of the original visibility data used to form the power spectra.", expected_type=str)
        self._norm_units = PSpecParam("norm_units", description="Power spectra normalization units, i.e. telescope units [Hz str] or cosmological [(h^-3) Mpc^3].", expected_type=str)
        self._filename1 = PSpecParam("filename1", description="filename of data from first dataset", expected_type=str)
        self._filename2 = PSpecParam("filename2", description="filename of data from second dataset", expected_type=str)
        self._label1 = PSpecParam("label1", description="label of data from first dataset", expected_type=str)
        self._label2 = PSpecParam("label2", description="label of data from second dataset", expected_type=str)
        self._git_hash = PSpecParam("git_hash", description="GIT hash of hera_pspec when pspec was generated.", expected_type=str)
        self._folded = PSpecParam("folded", description="if power spectra are folded (i.e. averaged) onto purely positive delay axis. Default is False", expected_type=bool)
        self._scalar_array = PSpecParam("scalar_array", description="Power spectrum normalization scalar from pspecbeam module.", expected_type=np.ndarray, form="(Nspws, Npols)")
        self._beamfile = PSpecParam("beamfile", description="filename of beam-model used to normalized pspectra.", expected_type=str)
        self._OmegaP = PSpecParam("OmegaP", description="Integral of unitless beam power over the sky [steradians].", form="(Nbeam_freqs, Npols)")
        self._OmegaPP = PSpecParam("OmegaP", description="Integral of unitless beam power squared over the sky [steradians].", form="(Nbeam_freqs, Npols)")
        self._beam_freqs = PSpecParam("beam_freqs", description="Frequency bins of the OmegaP and OmegaPP beam-integral arrays [Hz].", form="(Nbeam_freqs,)")
        self._cosmo = PSpecParam("cosmo", description="Instance of conversion.Cosmo_Conversions class.")

        # collect all parameters: required and non-required
        self._all_params = sorted(map(lambda p: p[1:], fnmatch.filter(self.__dict__.keys(), '_*')))

        # specify required params: these are required for read / write and self.check()
        self._req_params = ["Ntimes", "Nblpairts", "Nblpairs", "Nspwdlys", "Nspws", "Ndlys",
                            "Npols", "Nfreqs", "history", "data_array", "wgt_array", "integration_array",
                            "spw_array", "freq_array", "dly_array", "pol_array", "lst_1_array",
                            "lst_2_array", "time_1_array", "time_2_array", "blpair_array", "Nbls",
                            "bl_vecs", "bl_array", "channel_width", "telescope_location", "weighting",
                            "vis_units", "norm_units", "taper", "norm", "git_hash", "nsample_array",
                            'lst_avg_array', 'time_avg_array', 'folded', "scalar_array"]

        # all parameters must fall into one and only one of the following groups, which are used in __eq__
        self._immutables = ["Ntimes", "Nblpairts", "Nblpairs", "Nspwdlys", "Nspws", "Ndlys",
                            "Npols", "Nfreqs", "history", "Nbls", "channel_width", "weighting",
                            "vis_units", "filename1", "filename2", "label1", "label2", "norm",
                            "norm_units", "taper", "git_hash", "cosmo", "beamfile" ,'folded']
        self._ndarrays = ["spw_array", "freq_array", "dly_array", "pol_array", "lst_1_array",
                          'lst_avg_array', 'time_avg_array', "lst_2_array", "time_1_array",
                          "time_2_array", "blpair_array", "OmegaP", "OmegaPP", "beam_freqs",
                          "bl_vecs", "bl_array", "telescope_location", "scalar_array"]
        self._dicts = ["data_array", "wgt_array", "integration_array", "nsample_array"]

        # define which attributes are considred meta data. Large attrs should be constructed as datasets
        self._meta_dsets = ["lst_1_array", "lst_2_array", "time_1_array", "time_2_array", "blpair_array", 
                            "bl_vecs", "bl_array", 'lst_avg_array', 'time_avg_array', 'OmegaP', 'OmegaPP']
        self._meta_attrs = sorted(set(self._all_params) - set(self._dicts) - set(self._meta_dsets))
        self._meta = sorted(set(self._meta_dsets).union(set(self._meta_attrs)))

        # check all params are covered
        assert len(set(self._all_params) - set(self._dicts) - set(self._immutables) - set(self._ndarrays)) == 0

        # Default parameter values
        self.folded = False
        self.git_hash = version.git_hash

    def get_data(self, key, *args):
        """
        Slice into data_array with a specified data key in the format

        (spw, ((ant1, ant2), (ant3, ant4)), pol)

        or

        (spw, blpair-integer, pol)

        where spw is the spectral window integer, ant1 etc. are integers, 
        and pol is either a polarization string (ex. 'XX') or integer (ex. -5).

        Parameters
        ----------
        key : tuple, baseline-pair key

        Return
        ------
        data : complex ndarray with shape (Ntimes, Ndlys)
        """
        spw, blpairts, pol = self.key_to_indices(key, *args)

        # if data has been folded, return only positive delays
        if self.folded:
            Ndlys = self.data_array[spw].shape[1]
            return self.data_array[spw][blpairts, Ndlys//2+1:, pol]

        # else return all delays
        else:
            return self.data_array[spw][blpairts, :, pol]

    def get_wgts(self, key, *args):
        """
        Slice into wgt_array with a specified data key in the format

        (spw, ((ant1, ant2), (ant3, ant4)), pol)

        or

        (spw, blpair-integer, pol)

        where spw is the spectral window integer, ant1 etc. are integers, 
        and pol is either a polarization string (ex. 'XX') or integer (ex. -5).

        Parameters
        ----------
        key : tuple, baseline-pair key

        Return
        ------
        wgts : float ndarray with shape (2, Ntimes, Ndlys), where the zeroth axis holds
            [wgt_1, wgt_2] in that order
        """
        spw, blpairts, pol = self.key_to_indices(key, *args)

        return self.wgt_array[spw][blpairts, :, :, pol]

    def get_integrations(self, key, *args):
        """
        Slice into integration_array with a specified data key in the format

        (spw, ((ant1, ant2), (ant3, ant4)), pol)

        or

        (spw, blpair-integer, pol)

        where spw is the spectral window integer, ant1 etc. are integers, 
        and pol is either a polarization string (ex. 'XX') or integer (ex. -5).

        Parameters
        ----------
        key : tuple, baseline-pair key

        Return
        ------
        data : float ndarray with shape (Ntimes,)
        """
        spw, blpairts, pol = self.key_to_indices(key, *args)

        return self.integration_array[spw][blpairts, pol]

    def get_nsamples(self, key, *args):
        """
        Slice into nsample_array with a specified data key in the format

        (spw, ((ant1, ant2), (ant3, ant4)), pol)

        or

        (spw, blpair-integer, pol)

        where spw is the spectral window integer, ant1 etc. are integers, 
        and pol is either a polarization string (ex. 'XX') or integer (ex. -5).

        Parameters
        ----------
        key : tuple, baseline-pair key

        Return
        ------
        data : float ndarray with shape (Ntimes,)
        """
        spw, blpairts, pol = self.key_to_indices(key, *args)

        return self.nsample_array[spw][blpairts, pol]

    def get_dlys(self, key):
        """
        Get array of delays given a spectral window selection.

        Parameters
        ----------
        key : int, or tuple with integer
            Spectral window selection

        Returns
        -------
        dlys : float ndarray, contains delays in nanosec of pspectra given spw
        """
        indices = self.spw_to_indices(key)
        return self.dly_array[indices]

    def get_blpair_seps(self):
        """
        For each baseline-pair, get the average baseline separation in ENU frame in meters.

        Returns blp_avg_sep
        -------
        blp_avg_sep : float ndarray, shape=(Nblpairts,)
        """
        # get list of bl separations
        bl_vecs = self.get_ENU_bl_vecs()
        bls = self.bl_array.tolist()
        blseps = np.array(map(lambda bl: np.linalg.norm(bl_vecs[bls.index(bl)]), self.bl_array))

        # construct empty blp_avg_sep array
        blp_avg_sep = np.empty(self.Nblpairts, np.float)

        # construct blpair_bls
        blpairs = np.unique(self.blpair_array)
        bl1 = np.floor(blpairs / 1e6)
        blpair_bls = np.vstack([bl1, blpairs - bl1*1e6]).astype(np.int).T

        # iterate over blpairs
        for blp, bl in zip(blpairs, blpair_bls):
            avg_sep = np.mean([blseps[bls.index(bl[0])], blseps[bls.index(bl[1])]])
            inds = self.blpair_to_indices(blp)
            blp_avg_sep[inds] = avg_sep

        return blp_avg_sep

    def get_kperps(self, spw, little_h=True):
        """
        Get transverse (perpendicular) cosmological wavevector for each
        baseline-pair given an adopted cosmology and a spw selection.

        Parameters
        ----------
        spw : int, choice of spectral window

        little_h : boolean, optional
                Whether to have cosmological length units be h^-1 Mpc or Mpc
                Default: h^-1 Mpc

        Returns
        -------
        k_perp : float ndarray, transverse wave-vectors, shape=(Nblpairs,)
        """
        # assert cosmo
        assert hasattr(self, 'cosmo'), "self.cosmo must exist to form cosmological " \
            "wave-vectors. See self.set_cosmology()"

        # calculate mean redshift of band
        avg_z = self.cosmo.f2z(np.mean(self.freq_array[self.spw_to_indices(spw)]))

        # get kperps
        blpair_seps = self.get_blpair_seps()
        k_perp = blpair_seps * self.cosmo.bl_to_kperp(avg_z, little_h=little_h)

        return k_perp

    def get_kparas(self, spw, little_h=True):
        """
        Get radial (parallel) cosmological wavevectors for
        power spectra given an adopted cosmology and a spw selection.

        Parameters
        ----------
        spw : int, choice of spectral window

        little_h : boolean, optional
                Whether to have cosmological length units be h^-1 Mpc or Mpc
                Default: h^-1 Mpc

        Returns (k_perp, k_para)
        -------
        k_para : float ndarray, radial wave-vectors, shape=(Ndlys given spw)
        """
        # assert cosmo
        assert hasattr(self, 'cosmo'), "self.cosmo must exist to form cosmological " \
            "wave-vectors. See self.set_cosmology()"

        # calculate mean redshift of band
        avg_z = self.cosmo.f2z(np.mean(self.freq_array[self.spw_to_indices(spw)]))

        # get kparas
        k_para = self.get_dlys(spw) * self.cosmo.tau_to_kpara(avg_z, little_h=little_h)

        return k_para

    def convert_to_deltasq(self, little_h=True, inplace=True):
        """
        Convert from P(k) to Delta^2(k) by multiplying by k^3 / (2pi^2).

        The units of the output is therefore the current units (self.units) times h^3 Mpc^-3,
        where the h^3 is only included if little_h == True.

        Parameters
        ----------
        inplace : boolean, if True edit and overwrite arrays in self, else make a copy of self and return
        """
        # copy object
        if inplace:
            uvp = self
        else:
            uvp = copy.deepcopy(self)

        # loop over spectral windows
        for spw in range(uvp.Nspws):
            # get k vectors
            k_perp = uvp.get_kperps(spw, little_h=little_h)
            k_para = uvp.get_kparas(spw, little_h=little_h)
            k_mag = np.sqrt(k_perp[:, None, None]**2 + k_para[None, :, None]**2)

            # multiply into data
            uvp.data_array[spw] *= k_mag**3 / (2*np.pi**2)

        # edit units
        uvp.norm_units = "k^3 / (2pi^2)"

        if inplace == False:
            return uvp

    def blpair_to_antnums(self, blpair):
        """
        Convert baseline-pair integer to nested tuple of antenna numbers.

        Parameters
        ----------
        blpair : i12 int
            baseline-pair integer ID

        Return
        ------
        antnums : tuple
            nested tuple containing baseline-pair antenna numbers. Ex. ((ant1, ant2), (ant3, ant4))
        """
        return _blpair_to_antnums(blpair)

    def antnums_to_blpair(self, antnums):
        """
        Convert nested tuple of antenna numbers to baseline-pair integer.

        Parameters
        ----------
        antnums : tuple
            nested tuple containing integer antenna numbers for a baseline-pair.
            Ex. ((ant1, ant2), (ant3, ant4))

        Return
        ------
        blpair : i12 integer
            baseline-pair integer
        """
        return _antnums_to_blpair(antnums)

    def bl_to_antnums(self, bl):
        """
        Convert baseline (anntenna-pair) integer to nested tuple of antenna numbers.

        Parameters
        ----------
        bl : i6 int
            baseline integer ID

        Return
        ------
        antnums : tuple
            tuple containing baseline antenna numbers. Ex. (ant1, ant2)
        """
        return _bl_to_antnums(bl)

    def antnums_to_bl(self, antnums):
        """
        Convert tuple of antenna numbers to baseline integer.

        Parameters
        ----------
        antnums : tuple
            tuple containing integer antenna numbers for a baseline.
            Ex. (ant1, ant2)

        Return
        ------
        bl : i6 integer
            baseline integer
        """
        return _antnums_to_bl(antnums)

    def blpair_to_indices(self, blpair):
        """
        Convert a baseline-pair nested tuple ((ant1, ant2), (ant3, ant4)) or
        a baseline-pair integer into indices to index the blpairts axis of data_array.

        Parameters
        ----------
        blpair : nested tuple or blpair i12 integer, Ex. ((1, 2), (3, 4))
            or list of blpairs
        """
        # convert blpair to integer if fed as tuple
        if isinstance(blpair, tuple):
            blpair = [self.antnums_to_blpair(blpair)]
        elif isinstance(blpair, (np.int, int)):
            blpair = [blpair]
        elif isinstance(blpair, list):
            if isinstance(blpair[0], tuple):
                blpair = map(lambda blp: self.antnums_to_blpair(blp), blpair)
        # assert exists in data
        assert np.array(map(lambda b: b in self.blpair_array, blpair)).all(), "blpairs {} not all found in data".format(blpair)
        return np.arange(self.Nblpairts)[reduce(operator.add, map(lambda b: self.blpair_array == b, blpair))]

    def spw_to_indices(self, spw):
        """
        Convert a spectral window integer into a list of indices to index
        into the spwdlys axis of dly_array and/or freq_array.

        If self.folded == False, return indices for both positive and negative delay bins,
        else if self.folded == True, returns indices for only positive delay bins.

        Parameters
        ----------
        spw : int, spectral window index or list of indices
        """
        # convert to list if int
        if isinstance(spw, (np.int, int)):
            spw = [spw]

        # assert exists in data
        assert np.array(map(lambda s: s in self.spw_array, spw)).all(), "spws {} not all found in data".format(spw)

        # get select boolean array
        select = reduce(operator.add, map(lambda s: self.spw_array == s, spw))

        if self.folded:
            select[self.dly_array < 1e-10] = False

        return np.arange(self.Nspwdlys)[select]

    def pol_to_indices(self, pol):
        """
        Map a polarization integer or str to its index in pol_array

        Parameters
        ----------
        pol : str or int, polarization string (ex. 'XX') or integer (ex. -5)
            or list of strs or ints

        Returns
        -------
        indices : int, index of pol in pol_array
        """
        # convert pol to int if str
        if isinstance(pol, (str, np.str)):
            pol = [uvutils.polstr2num(pol)]
        elif isinstance(pol, (int, np.int)):
            pol = [pol]
        elif isinstance(pol, (list, tuple)):
            for i in range(len(pol)):
                if isinstance(pol[i], (np.str, str)):
                    pol[i] = uvutils.polstr2num(pol[i])

        # ensure all pols exist in data
        assert np.array(map(lambda p: p in self.pol_array, pol)).all(), "pols {} not all found in data".format(pol)

        indices = np.arange(self.Npols)[reduce(operator.add, map(lambda p: self.pol_array == p, pol))]
        return indices

    def time_to_indices(self, time, blpairs=None):
        """
        Convert a time [Julian Date] from self.time_avg_array to an array that 
        indexes the elements at which it appears in that array. Can optionally 
        take a blpair selection to further select the indices at which both 
        that time and blpair are satisfied.

        Parameters
        ----------
        time : float
            Julian Date time from self.time_avg_array, Ex: 2458042.12242

        blpairs : tuple or int, optional
            List of blpair tuples or integers that further selects the elements 
            at which both time and blpairs are satisfied.

        Returns
        -------
        indices : integer ndarray
            Contains indices at which selection is satisfied along the 
            blpairts axis.
        """
        time_select = np.isclose(self.time_avg_array, time, rtol=1e-10)
        if blpairs is None:
            return np.arange(self.Nblpairts)[time_select]
        else:
            blp_select = np.zeros(self.Nblpairts, np.bool)
            if isinstance(blpairs, (tuple, int, np.int)):
                blpairs = [blpairs]
            for blp in blpairs:
                blp_select[self.blpair_to_indices(blp)] = True
            time_select *= blp_select
            return np.arange(self.Nblpairts)[time_select]

    def key_to_indices(self, key, *args):
        """
        Convert a data key into relevant slice arrays. A data key takes the form

        (spw_integer, ((ant1, ant2), (ant3, ant4)), pol_string)

        or

        (spw, blpair-integer, pol)

        where spw is the spectral window integer, ant1 etc. are integers, 
        and pol is either a polarization string (ex. 'XX') or integer (ex. -5).

        One can also expand this key into the kwarg slots, such that 
        key=spw, key2=blpair, and key3=pol.
    
        The key can also be a dictionary in the form
        key = {
            'spw' : spw_integer,
            'blpair' : ((ant1, ant2), (ant3, ant4))
            'pol' : pol_string
            }
        and it will parse the dictionary for you.

        Parameters
        ----------
        key : tuple, baseline-pair key

        Returns (spw, blpairts, pol)
        -------
        spw : integer
        blpairts : list of integers to apply along blpairts axis
        pol : integer
        """
        # assert key length
        if len(args) == 0:
            assert len(key) == 3, "length of key must be 3."
            if isinstance(key, (odict, dict)):
                key = (key['spw'], key['blpair'], key['pol'])
        elif len(args) > 0:
            assert len(args) == 2, "length of key must be 3."
            assert isinstance(args[0], (tuple, int, np.int)) and isinstance(args[1], (np.str, str, int, np.int)), "key must be ordered as (spw, blpair, pol)"
            key = (key, args[0], args[1])

        # assign key elements
        spw = key[0]
        blpair = key[1]
        pol = key[2]

        # assert types
        assert isinstance(spw, (int, np.int)), "spw must be an integer"
        assert isinstance(blpair, (int, np.int, tuple)), "blpair must be an integer or nested tuple"
        assert isinstance(pol, (np.str, str, np.int, int)), "pol must be a string or integer"

        # convert blpair to int if not int
        if type(blpair) == tuple:
            blpair = self.antnums_to_blpair(blpair)

        # convert pol to int if str
        if type(pol) in (str, np.str):
            pol = uvutils.polstr2num(pol)

        # check attribuets exists in data
        assert spw in self.spw_array, "spw {} not found in data".format(spw)
        assert blpair in self.blpair_array, "blpair {} not found in data".format(blpair)
        assert pol in self.pol_array, "pol {} not found in data".format(pol)

        # index polarization array
        pol = self.pol_to_indices(pol)
        # index blpairts
        blpairts = self.blpair_to_indices(blpair)

        return spw, blpairts, pol

    def select(self, spws=None, bls=None, only_pairs_in_bls=True, blpairs=None, 
               times=None, pols=None, inplace=True):
        """
        Select function for selecting out certain slices of the data.

        Parameters
        ----------
        spws : list of spectral window integers to select

        bls : list of i6 baseline integers or baseline tuples (e.g. (2,3))
            Select all baseline-pairs whose first _or_ second baseline are in 
            bls list. This changes if only_pairs_in_bls == True.

        only_pairs_in_bls : bool, optional
            If True, keep only baseline-pairs whose first _and_ second baseline
            are found in bls list. Default: True.

        blpairs : list of baseline-pair tuples or integers
            List of baseline-pairs to keep. If bls is also fed, this list is 
            concatenated onto the baseline-pair list constructed from from the 
            bls selection.

        times : float ndarray of times from the time_avg_array to keep.

        pols : list of polarization strings or integers 
            List of polarizations to keep. See pyuvdata.utils.polstr2num for 
            acceptable options.

        inplace : boolean, optional
            If True, edit and overwrite arrays in self, else make a copy of 
            self and return. Default: True.
        """
        if inplace:
            uvp = self
        else:
            uvp = copy.deepcopy(self)

        _select(uvp, spws=spws, bls=bls, only_pairs_in_bls=only_pairs_in_bls, 
                blpairs=blpairs, times=times, pols=pols)

        if inplace == False:
            return uvp

    def get_ENU_bl_vecs(self):
        """
        return baseline vector array in TOPO (ENU) frame in meters, with 
        matched ordering of self.bl_vecs.
        """
        return uvutils.ENU_from_ECEF((self.bl_vecs + self.telescope_location).T, \
              *uvutils.LatLonAlt_from_XYZ(self.telescope_location)).T
    
    
    
    def read_from_group(self, grp, just_meta=False, spws=None, bls=None, 
                        blpairs=None, times=None, pols=None, 
                        only_pairs_in_bls=False):
        """
        Clear current UVPSpec object and load in data from specified HDF5 group.
        
        Parameters
        ----------
        grp : HDF5 group
            HDF5 group to load data from.

        just_meta : bool, optional
            If True, read-in metadata but ignore data, wgts and integration 
            arrays. Default: False.

        spws : list of tuple, optional
            List of spectral window integers to select. Default: None (loads 
            all channels).

        bls : list of i6 baseline integers or baseline tuples
            Select all baseline-pairs whose first _or_ second baseline are in 
            the list. This changes if only_pairs_in_bls == True.
            Example tuple: (2, 3). Default: None (loads all bl pairs).
        
        blpairs : list of baseline-pair tuples or integers
            List of baseline pairs to keep. If bls is also fed, this list is 
            concatenated onto the baseline-pair list constructed from from the 
            bls selection.
 
        times : float ndarray
            Times from the time_avg_array to keep.
        
        pols : list of str or int
            List of polarization strings or integers to keep. See 
            pyuvdata.utils.polstr2num for acceptable options.
        
        only_pairs_in_bls : bool, optional
            If True, keep only baseline-pairs whose first _and_ second baseline
            are found in the 'bls' list. Default: False.
        """
        # Clear all data in the current object
        self._clear()
        
        # Load-in meta data
        for k in grp.attrs:
            if k in self._meta_attrs:
                setattr(self, k, grp.attrs[k])
        for k in grp:
            if k in self._meta_dsets:
                setattr(self, k, grp[k][:])
        
        # Use _select() to pick out only the requested baselines/spws
        if just_meta:
            _select(self, spws=spws, bls=bls,
                    only_pairs_in_bls=only_pairs_in_bls, 
                    blpairs=blpairs, times=times, pols=pols)
        else:
            _select(self, spws=spws, bls=bls, 
                    only_pairs_in_bls=only_pairs_in_bls, 
                    blpairs=blpairs, times=times, pols=pols, 
                    h5file=grp)
        
        # handle cosmo
        if hasattr(self, 'cosmo'):
            self.cosmo = conversions.Cosmo_Conversions(**ast.literal_eval(self.cosmo))

        self.check(just_meta=just_meta)
    
    
    def read_hdf5(self, filepath, just_meta=False, spws=None, bls=None,
                  blpairs=None, times=None, pols=None, 
                  only_pairs_in_bls=False):
        """
        Clear current UVPSpec object and load in data from an HDF5 file.

        Parameters
        ----------
        filepath : str, path to HDF5 file

        just_meta : bool, optional
            If True, read-in metadata but ignore data, wgts and integration 
            arrays. Default: False.

        spws : list of tuple, optional
            List of spectral window integers to select. Default: None (loads 
            all channels).

        bls : list of i6 baseline integers or baseline tuples
            Select all baseline-pairs whose first _or_ second baseline are in 
            the list. This changes if only_pairs_in_bls == True.
            Example tuple: (2, 3). Default: None (loads all bl pairs).

        blpairs : list of baseline-pair tuples or integers
            List of baseline pairs to keep. If bls is also fed, this list is 
            concatenated onto the baseline-pair list constructed from from the 
            bls selection.
 
        times : float ndarray
            Times from the time_avg_array to keep.
        
        pols : list of str or int
            List of polarization strings or integers to keep. See 
            pyuvdata.utils.polstr2num for acceptable options.
        
        only_pairs_in_bls : bool, optional
            If True, keep only baseline-pairs whose first _and_ second baseline
            are found in the 'bls' list. Default: False.
        """
        # Open file descriptor and read data
        with h5py.File(filepath, 'r') as f:
            self.read_from_group(f, just_meta=just_meta, spws=spws, bls=bls, 
                                 only_pairs_in_bls=only_pairs_in_bls)
    
    def write_to_group(self, group, run_check=True):
        """
        Write UVPSpec data into an HDF5 group.
        """
        # Run check
        if run_check: self.check()
        
        # Check whether the group already contains info
        # TODO
        
        # Write meta data
        for k in self._meta_attrs:
            if hasattr(self, k):
                # handle cosmo
                if k == 'cosmo':
                    group.attrs['cosmo'] = str(getattr(self, k).get_params())
                    continue
                group.attrs[k] = getattr(self, k)
        for k in self._meta_dsets:
            if hasattr(self, k):
                group.create_dataset(k, data=getattr(self, k))

        # Iterate over spectral windows and create datasets
        for i in np.unique(self.spw_array):
            group.create_dataset("data_spw{}".format(i), 
                                 data=self.data_array[i], 
                                 dtype=np.complex)
            group.create_dataset("wgt_spw{}".format(i), 
                                 data=self.wgt_array[i], 
                                 dtype=np.float)
            group.create_dataset("integration_spw{}".format(i), 
                                 data=self.integration_array[i], 
                                 dtype=np.float)
            group.create_dataset("nsample_spw{}".format(i), 
                                 data=self.nsample_array[i], 
                                 dtype=np.float)
    
    def write_hdf5(self, filepath, overwrite=False, run_check=True):
        """
        Write a UVPSpec object to HDF5 file.

        Parameters
        ----------
        filepath : str, filepath for output file

        overwrite : boolean, overwrite output file if it exists

        run_check : boolean, run UVPSpec check before writing to file
        """
        # Check output
        if os.path.exists(filepath) and overwrite is False:
            raise IOError("{} exists, not overwriting...".format(filepath))
        elif os.path.exists(filepath) and overwrite is True:
            print "{} exists, overwriting...".format(filepath)
            os.remove(filepath)
        
        # Write file
        with h5py.File(filepath, 'w') as f:
            self.write_to_group(f, run_check=run_check)


    def set_cosmology(self, new_cosmo, overwrite=False, new_beam=None, 
                      verbose=True):
        """
        Set the cosmology for this UVPSpec object by passing an instance of 
        conversions.Cosmo_Conversions and assigning it to self.cosmo, in 
        addition to re-computing power spectrum normalization quantities like 
        self.scalar_array. Because this will attempt to recompute the scalar_array,
        the beam-related metadata (OmegaP, OmegaPP and beam_freqs) must exist in self. 
        If they do not, or if you'd like to overwrite them with a new beam, you can 
        pass a UVBeam object or path to a beam file via the new_beam kwarg.

        If self.cosmo already exists then you are attempting to overwrite the 
        currently adopted cosmology, which will only proceed if overwrite == True. 
        If overwrite == True, then this module will overwrite self.cosmo. It will 
        also recompute the power spectrum normalization scalar (using pspecbeam) 
        and will overwrite the values in self.scalar_array. It will then propagate 
        these re-normalization changes into the data_array by multiplying the data by 
        new_scalar_array / old_scalar_array.

        Parameters
        ----------
        new_cosmo : Cosmo_Conversions instance or cosmological parameter dictionary
            The new cosmology you want to adopt for this UVPSpec object.

        overwrite : boolean, if True, overwrite self.cosmo if it already exists

        new_beam : pspecbeam.PSpecBeamUV object or path to beam file.
            The new beam you want to adopt for this UVPSpec object.

        verbose : boolean, if True, rerport feedback to stdout.
        """
        if hasattr(self, 'cosmo') and overwrite == False:
            print("self.cosmo exists and overwrite == False, not overwriting...")
            return

        else:
            if (not hasattr(self, 'OmegaP') or not hasattr(self, 'OmegaPP') or not hasattr(self, 'beam_freqs')) and new_beam is None:
                print "In order to set the cosmology, self.OmegaP, self.OmegaPP and self.beam_freqs " \
                      "must exist, or you need to pass a PSpecBeamUV object or a path to a beam " \
                      "file as new_beam."
                return

        # overwrite beam quantities
        if new_beam is not None:
            if verbose: print "Updating beam data with {}".format(new_beam)
            if isinstance(new_beam, (str, np.str)):
                # PSpecBeamUV will adopt a default cosmology upon instantiation, but this doesn't matter
                # for what we need from it
                new_beam = pspecbeam.PSpecBeamUV(new_beam)
            self.OmegaP, self.OmegaPP = new_beam.get_Omegas(self.pol_array)
            self.beam_freqs = new_beam.beam_freqs

        # update cosmo
        if isinstance(new_cosmo, (dict, odict)):
            new_cosmo = conversions.Cosmo_Conversions(**new_cosmo)
        if verbose: print("setting cosmology: \n{}".format(new_cosmo))
        self.cosmo = new_cosmo

        # update scalar_array
        if verbose: print("Updating scalar array and re-normalizing power spectra")
        for spw in range(self.Nspws):
            for j, pol in enumerate(self.pol_array):
                scalar = self.compute_scalar(spw, pol, num_steps=1000, 
                                             little_h=True, noise_scalar=False)

                # renormalize power spectra with new scalar
                self.data_array[spw][:, :, j] *= scalar / self.scalar_array[spw, j]

                # update self.scalar_array element
                self.scalar_array[spw, j] = scalar

        # update self.units if pspectra were not originally in cosmological units
        if "Mpc" not in self.norm_units:
            self.norm_units = "h^-3 Mpc^3"

    def check(self, just_meta=False):
        """
        Run checks

        Just_meta : bool, if True, only check meta-data
        """
        # check required parameters exist
        if just_meta:
            req_metas = sorted(set(self._req_params).intersection(set(self._meta)))
            for p in req_metas:
                assert hasattr(self, p), "required parameter {} hasn't been defined".format(p)
        else:
            for p in self._req_params:
                assert hasattr(self, p), "required parameter {} hasn't been defined".format(p)
            # check data
            assert isinstance(self.data_array, (dict, odict)), "self.data_array must be a dictionary type"
            assert np.min(map(lambda k: self.data_array[k].dtype in (np.complex, complex, np.complex128), self.data_array.keys())), "self.data_array values must be complex type"
            # check wgts
            assert isinstance(self.wgt_array, (dict, odict)), "self.wgt_array must be a dictionary type"
            assert np.min(map(lambda k: self.wgt_array[k].dtype in (np.float, float), self.wgt_array.keys())), "self.wgt_array values must be float type"
            # check integration
            assert isinstance(self.integration_array, (dict, odict)), "self.integration_array must be a dictionary type"
            assert np.min(map(lambda k: self.integration_array[k].dtype in (np.float, float, np.float64), self.integration_array.keys())), "self.integration_array values must be float type"
            # check nsample
            assert isinstance(self.nsample_array, (dict, odict)), "self.nsample_array must be a dictionary type"
            assert np.min(map(lambda k: self.nsample_array[k].dtype in (np.float, float, np.float64), self.nsample_array.keys())), "self.nsample_array values must be float type"

    def _clear(self):
        """
        Clear UVPSpec of all parameters. Warning: this cannot be undone.
        """
        for p in self._all_params:
            if hasattr(self, p):
                delattr(self, p)
    
    def __str__(self):
        """
        Output useful info about UVPSpec object.
        """
        s = ""
        s += " ATTRIBUTES\n"
        s += "-"*12 + "\n"
        for k in self._meta_attrs:
            if hasattr(self, k) and 'history' not in k:
                y = getattr(self, k)
                if isinstance(y, np.ndarray):
                    s += "%18s: shape %s\n" % (k, y.shape)
                else:
                    s += "%18s: %s\n" % (k, y)
        
        s += "\n DATASETS\n"
        s += "-"*12 + "\n"
        for k in self._meta_dsets:
            if hasattr(self, k):
                s += "%18s: shape %s\n" % (k, getattr(self, k).shape)
        return s
    
    def __eq__(self, other):
        """ Check equivalence between attributes of two UVPSpec objects """
        try:
            for p in self._all_params:
                if p not in self._req_params \
                  and (not hasattr(self, p) and not hasattr(other, p)):
                    continue
                if p in self._immutables:
                    assert getattr(self, p) == getattr(other, p)
                elif p in self._ndarrays:
                    assert np.isclose(getattr(self, p), getattr(other, p)).all()
                elif p in self._dicts:
                    for i in getattr(self, p):
                        assert np.isclose(getattr(self, p)[i], \
                               getattr(other, p)[i]).all()
        except AssertionError:
            return False

        return True

    @property
    def units(self):
        """ return power spectrum units. See self.vis_units and self.norm_units."""
        return "({})^2 {}".format(self.vis_units, self.norm_units)

    def generate_noise_spectra(self, spw, pol, Tsys, blpairs=None, little_h=True, 
                               form='Pk', num_steps=2000, real=True):
        """
        Generate the expected 1-sigma noise power spectrum given a selection of 
        spectral window, system temp., and polarization. This estimate is 
        constructed as:

        P_N = scalar * (Tsys * 1e3)^2 / (integration_time) / sqrt(Nincoherent)
              [mK^2 h^-3 Mpc^3]

        where scalar is the cosmological and beam scalar (i.e. X2Y * Omega_eff) 
        calculated from pspecbeam with noise_scalar = True, integration_time is 
        in seconds and comes from self.integration_array and Nincoherent is the 
        number of incoherent averaging samples and comes from 
        self.nsample_array.

        If the polarization specified is a pseudo Stokes pol (I, Q, U or V) 
        then an extra factor of 2 is divided.
        If form == 'DelSq' then a factor of k^3 / (2pi^2) is multiplied.
        If real is True, a factor of sqrt(2) is divided to account for 
        discarding imaginary noise component.

        For more details, see hera_pspec.noise.Sensitivity.calc_P_N, and 
        Cheng et al. 2018.

        The default units of P_N are mK^2 h^-3 Mpc^3 (if little_h=True and 
        form='Pk'), but is different if those kwargs are altered.

        Parameters
        ----------
        spw : int, spectral window index to generate noise curve for

        pol : str or int, polarization selection in form of str 
            (e.g. 'I' or 'Q' or 'xx') or int (e.g. -5 or -6)

        Tsys : float, system temperature in Kelvin

        blpairs : list of unique blair tuples or i12 integers to calculate 
            noise spectrum for default is to calculate for baseline pairs

        little_h : boolean, optional
                Whether to have cosmological length units be h^-1 Mpc or Mpc
                Default: h^-1 Mpc

        form : str, form of pspectra, P(k) or Delta^2(k), options=['Pk', 'DelSq']

        num_steps : int, number of frequency bins to use in integrating power 
            spectrum scalar in pspecbeam.

        real : boolean, if True assumes the real component of complex power 
            spectrum is used, amd will divide P_N by an extra sqrt(2), 
            otherwise assume power spectra are complex and keep P_N as is.

        Returns (P_N)
        -------
        P_N : dictionary containing blpair integers as keys and float ndarrays 
            of noise power spectra as values, with ndarrays having shape 
            (Ntimes, Ndlys).
        """
        # assert polarization type
        if isinstance(pol, (np.int, int)):
            pol = uvutils.polnum2str(pol)

        # get polarization index
        pol_ind = self.pol_to_indices(pol)

        # get frequency band
        freqs = self.freq_array[self.spw_to_indices(spw)]

        # calculate scalar
        scalar = self.compute_scalar(spw, pol, num_steps=num_steps, little_h=little_h, noise_scalar=True)

        # Get k vectors
        if form == 'DelSq':
            k_perp = self.get_kperps(spw, little_h=little_h)
            k_para = self.get_kparas(spw, little_h=little_h)
            k_mag = np.sqrt(k_perp[:, None]**2 + k_para[None, :]**2)

        # get blpairs
        if blpairs is None:
            blpairs = np.unique(self.blpair_array)
        elif isinstance(blpairs[0], tuple):
            blpairs = map(lambda blp: self.antnums_to_blpair(blp), blpairs)

        # get dlys
        dlys = self.get_dlys(spw)

        # Iterate over blpairs to get P_N
        P_N = odict()
        for i, blp in enumerate(blpairs):
            # get indices
            inds = self.blpair_to_indices(blp)

            P_blp = []
            # iterate over time axis
            for j, ind in enumerate(inds):
                # get integration time and n_samp
                t_int = self.integration_array[spw][ind, pol_ind]
                n_samp = self.nsample_array[spw][ind, pol_ind]

                # get kvecs
                if form == 'DelSq':
                    k = k_mag[ind]
                else:
                    k = None

                # get pn
                pn = noise.calc_P_N(scalar, Tsys, t_int, k=k, Nincoherent=n_samp, form=form)

                # put into appropriate form
                if form == 'Pk':
                    pn = np.ones(len(dlys), np.float) * pn

                # if pseudo stokes pol (as opposed to linear or circular pol), 
                # divide by extra factor of 2
                if isinstance(pol, (np.str, str)):
                    pol = uvutils.polstr2num(pol)
                if pol in (1, 2, 3, 4):
                    # pseudo stokes pol
                    pn /= 2.0
                # if real divide by sqrt(2)
                if real:
                    pn /= np.sqrt(2)

                # append to P_blp
                P_blp.append(pn)

            P_N[blp] = np.array(P_blp)

        return P_N

    def average_spectra(self, blpair_groups=None, time_avg=False, inplace=True):
        """
        Average power spectra across the baseline-pair-time axis, weighted by 
        each spectrum's integration time.
        
        This is an "incoherent" average, in the sense that this averages power 
        spectra, rather than visibility data. The 'nsample_array' and 
        'integration_array' will be updated to reflect the averaging.

        In the case of averaging across baseline pairs, the resultant averaged 
        spectrum is assigned to the zeroth blpair in the group. In the case of 
        time averaging, the time and LST arrays are assigned to the mean of the 
        averaging window.

        Note that this is designed to be separate from spherical binning in k: 
        here we are not connecting k_perp modes to k_para modes. However, if 
        blpairs holds groups of iso baseline separation, then this is 
        equivalent to cylindrical binning in 3D k-space.

        If you want help constructing baseline-pair groups from baseline 
        groups, see self.get_blpair_groups_from_bl_groups.

        Parameters
        ----------
        blpair_groups : list of baseline-pair groups
            i.e. list of list of tuples or integers. 
            All power spectra in a baseline-pair group are averaged together. 
            If a baseline-pair exists in more than one group, a warning is 
            raised.
            Ex: blpair_groups = [ [((1, 2), (1, 2)), ((2, 3), (2, 3))], [((4, 6), (4, 6))]] or
                blpair_groups = [ [1002001002, 2003002003], [4006004006] ]

        time_avg : boolean, if True, average power spectra across the time axis.

        inplace : bool, if True, edit data in self, else make a copy and return

        Notes
        -----
        Currently, every baseline-pair in a blpair group must have the same Ntimes, 
        unless time_avg=True. Future versions may support baseline-pair averaging of 
        heterogeneous time arrays. This includes the scenario of repeated blpairs 
        (e.g. in bootstrapping), which will return multiple copies of their time_array.
        """
        if inplace:
            uvp = self
        else:
            uvp = copy.deepcopy(self)

        # if blpair_groups were fed, enforce type and structure
        if blpair_groups is not None:
            # enforce shape of blpair_groups
            assert isinstance(blpair_groups[0], list), "blpair_groups must be fed as a list of baseline-pair lists. See docstring."

            # convert blpair_groups to list of blpair group integers
            if isinstance(blpair_groups[0][0], tuple):
                new_blpair_groups = []
                for blpg in blpair_groups:
                    new_blpair_groups.append(map(lambda blp: uvp.antnums_to_blpair(blp), blpg))
                blpair_groups = new_blpair_groups

        # if not, each baseline pair is its own group
        else:
            blpair_groups = map(lambda blp: [blp], np.unique(uvp.blpair_array))

        # print warning if a blpair appears more than once in all of blpair_groups
        all_blpairs = [item for sublist in blpair_groups for item in sublist]
        if len(set(all_blpairs)) < len(all_blpairs): print "Warning: some baseline-pairs are repeated between blpair averaging groups..."

        # for baseline pairs not in blpair_groups, add them as their own group
        extra_blpairs = set(uvp.blpair_array) - set(all_blpairs)
        blpair_groups += map(lambda blp: [blp], extra_blpairs)

        # create new data arrays
        data_array = odict()
        wgts_array = odict()
        ints_array = odict()
        nsmp_array = odict()

        # Iterate over spectral windows
        for spw in range(uvp.Nspws):
            spw_data = []
            spw_wgts = []
            spw_ints = []
            spw_nsmp = []

            # iterate over polarizations
            for i, p in enumerate(uvp.pol_array):
                pol_data = []
                pol_wgts = []
                pol_ints = []
                pol_nsmp = []

                # iterate over baseline-pair groups
                for j, blpg in enumerate(blpair_groups):
                    bpg_data = []
                    bpg_wgts = []
                    bpg_ints = []
                    bpg_nsmp = []
                    w_list = []

                    # iterate within a baseline-pair group and get integration-weighted data
                    for k, blp in enumerate(blpg):
                        nsmp = uvp.get_nsamples(spw, blp, p)[:, None]
                        data = uvp.get_data(spw, blp, p)
                        wgts = uvp.get_wgts(spw, blp, p)
                        ints = uvp.get_integrations(spw, blp, p)[:, None]
                        w = (ints * np.sqrt(nsmp))

                        # take time average if desired
                        if time_avg:
                            data = (np.sum(data * w, axis=0) / np.sum(w, axis=0).clip(1e-10, np.inf))[None]
                            wgts = (np.sum(wgts * w[:, None], axis=0) / np.sum(w, axis=0).clip(1e-10, np.inf)[:, None])[None] 
                            ints = (np.sum(ints * w, axis=0) / np.sum(w, axis=0).clip(1e-10, np.inf))[None]
                            nsmp = np.sum(nsmp, axis=0)[None]
                            w = np.sum(w, axis=0)[None]

                        bpg_data.append(data * w)
                        bpg_wgts.append(wgts * w[:, None])
                        bpg_ints.append(ints * w)
                        bpg_nsmp.append(nsmp)
                        w_list.append(w)

                    # take integration-weighted averages
                    bpg_data = np.sum(bpg_data, axis=0) / np.sum(w_list, axis=0).clip(1e-10, np.inf)
                    bpg_wgts = np.sum(bpg_wgts, axis=0) / np.sum(w_list, axis=0).clip(1e-10, np.inf)[:, None]
                    bpg_nsmp = np.sum(bpg_nsmp, axis=0)
                    bpg_ints = np.sum(bpg_ints, axis=0) / np.sum(w_list, axis=0).clip(1e-10, np.inf)
                    w_list = np.sum(w_list, axis=0)

                    # append to lists
                    pol_data.extend(bpg_data)
                    pol_wgts.extend(bpg_wgts)
                    pol_ints.extend(bpg_ints)
                    pol_nsmp.extend(bpg_nsmp)

                # append to lists
                spw_data.append(pol_data)
                spw_wgts.append(pol_wgts)
                spw_ints.append(pol_ints)
                spw_nsmp.append(pol_nsmp)

            # append to dictionaries
            data_array[spw] = np.moveaxis(spw_data, 0, -1)
            wgts_array[spw] = np.moveaxis(spw_wgts, 0, -1)
            ints_array[spw] = np.moveaxis(spw_ints, 0, -1)[:, 0, :]
            nsmp_array[spw] = np.moveaxis(spw_nsmp, 0, -1)[:, 0, :]

        # iterate over blpair groups one more time to assign metadata
        time_1 = []
        time_2 = []
        time_avg_arr = []
        lst_1 = []
        lst_2 = []
        lst_avg_arr = []
        blpair_arr = []
        bl_arr = []
        for i, blpg in enumerate(blpair_groups):
            # get blpairts indices for zeroth blpair in this group
            blpairts = uvp.blpair_to_indices(blpg[0])
            # assign meta-data
            bl_arr.extend(list(_blpair_to_bls(blpg[0])))
            if time_avg:
                blpair_arr.append(blpg[0])
                time_1.extend([np.mean(uvp.time_1_array[blpairts])])
                time_2.extend([np.mean(uvp.time_2_array[blpairts])])
                time_avg_arr.extend([np.mean(uvp.time_avg_array[blpairts])])
                lst_1.extend([np.mean(np.unwrap(uvp.lst_1_array[blpairts]))%(2*np.pi)])
                lst_2.extend([np.mean(np.unwrap(uvp.lst_2_array[blpairts]))%(2*np.pi)])
                lst_avg_arr.extend([np.mean(np.unwrap(uvp.lst_avg_array[blpairts]))%(2*np.pi)])
            else:
                blpair_arr.extend(np.ones_like(blpairts, np.int) * blpg[0])
                time_1.extend(uvp.time_1_array[blpairts])
                time_2.extend(uvp.time_2_array[blpairts])
                time_avg_arr.extend(uvp.time_avg_array[blpairts])
                lst_1.extend(uvp.lst_1_array[blpairts])
                lst_2.extend(uvp.lst_2_array[blpairts])
                lst_avg_arr.extend(uvp.lst_avg_array[blpairts])

        # update arrays
        bl_arr = np.array(sorted(set(bl_arr)))
        bl_vecs = np.array(map(lambda bl: uvp.bl_vecs[uvp.bl_array.tolist().index(bl)], bl_arr))

        # assign to uvp
        uvp.Ntimes = len(np.unique(time_avg_arr))
        uvp.Nblpairts = len(time_avg_arr)
        uvp.Nblpairs = len(np.unique(blpair_arr))
        uvp.Nbls = len(bl_arr)
        uvp.bl_array = bl_arr
        uvp.bl_vecs = bl_vecs
        uvp.blpair_array = np.array(blpair_arr)
        uvp.time_1_array = np.array(time_1)
        uvp.time_2_array = np.array(time_2)
        uvp.time_avg_array = np.array(time_avg_arr)
        uvp.lst_1_array = np.array(lst_1)
        uvp.lst_2_array = np.array(lst_2)
        uvp.lst_avg_array = np.array(lst_avg_arr)
        uvp.data_array = data_array
        uvp.integration_array = ints_array
        uvp.wgt_array = wgts_array
        uvp.nsample_array = nsmp_array
        if hasattr(self, 'label1'): uvp.label1 = self.label1
        if hasattr(self, 'label2'): uvp.label2 = self.label2

        uvp.check()

        if inplace == False:
            return uvp

    def fold_spectra(self):
        """
        Fold power spectra: average bandpowers from matching positive and degative delay bins onto a purely
        positive delay axis. Negative delay bins are still populated, but are filled with zero
        power. Will only work if self.folded == False, i.e. data is currently unfolded across
        negative and positive delay. Because this averages the data, the nsample array is multiplied
        by a factor of 2. Warning: this operation cannot be undone.
        """
        # assert folded is False
        assert self.folded == False, "cannot fold power spectra if self.folded == True"

        # Iterate over spw
        for spw in range(self.Nspws):

            # get number of dly bins
            Ndlys = len(self.get_dlys(spw))

            if Ndlys % 2 == 0:
                # even number of dlys
                left = self.data_array[spw][:, 1:Ndlys//2, :][:, ::-1, :]
                right = self.data_array[spw][:, Ndlys//2+1:, :]
                self.data_array[spw][:, Ndlys//2+1:, :] = np.mean([left, right], axis=0)
                self.data_array[spw][:, :Ndlys//2, :] = 0.0
                self.nsample_array[spw] *= 2.0

            else:
                # odd number of dlys
                left = self.data_array[spw][:, :Ndlys//2, :][:, ::-1, :]
                right = self.data_array[spw][:, Ndlys//2+1:, :]   
                self.data_array[spw][:, Ndlys//2+1:, :] = np.mean([left, right], axis=0)
                self.data_array[spw][:, :Ndlys//2, :] = 0.0
                self.nsample_array[spw] *= 2.0

        self.folded = True

    def get_blpair_groups_from_bl_groups(self, blgroups, only_pairs_in_bls=False):
        """
        Get baseline pair matches from a list of baseline groups.

        Parameters
        ----------
        blgroups : list of baseline groups, which themselves are lists of baseline tuples or baseline i6 integers
            Ex: [ [(1, 2), (2, 3), (3, 4)], [(1, 4), (2, 5)] ]

        only_pairs_in_bls : bool, if True, select only baseline-pairs whose first _and_ second baseline
            are both found in each baseline group.

        Returns blpair_groups
        -------
        blpair_groups : list of blpair groups, which themselves are lists of blpair integers
        """
        blpair_groups = []
        for blg in blgroups:
            blp_select = _get_blpairs_from_bls(self, blg, only_pairs_in_bls=only_pairs_in_bls)
            blp = sorted(set(self.blpair_array[blp_select]))
            if len(blp) > 0:
                blpair_groups.append(blp)

        return blpair_groups

    def compute_scalar(self, spw, pol, num_steps=1000, little_h=True, noise_scalar=False):
        """
        Compute power spectrum normalization scalar given an adopted cosmology and a beam model.
        See pspecbeam.PSpecBeamBase.compute_pspec_scalar for details.

        Parameters
        ----------
        spw : integer, spectral window selection

        pol : string or integer, polarization selection

        num_steps : integer, number of integration bins along frequency in computing scalar

        noise_scalar : boolean, if True calculate noise pspec scalar, else calculate normal pspec scalar
            See pspecbeam.py for difference between normal scalar and noise scalar.

        Returns
        -------
        scalar : float, power spectrum normalization scalar
        """
        # make assertions
        assert hasattr(self, 'cosmo'), "self.cosmo object must exist to compute scalar. See self.set_cosmology()"
        assert hasattr(self, 'OmegaP') and hasattr(self, "OmegaPP") and hasattr(self, "beam_freqs"), "self.OmegaP, "\
            "self.OmegaPP and self.beam_freqs must exist to compute scalar."

        # get freq array of selected spw
        spw_freqs = self.freq_array[self.spw_to_indices(spw)]

        # compute scalar
        OP = self.OmegaP[:, self.pol_to_indices(pol)].squeeze()
        OPP = self.OmegaPP[:, self.pol_to_indices(pol)].squeeze()
        scalar = pspecbeam._compute_pspec_scalar(self.cosmo, self.beam_freqs, OPP / OP**2, spw_freqs, 
                                                 num_steps=num_steps, taper=self.taper, little_h=little_h, 
                                                 noise_scalar=noise_scalar)

        return scalar


def _get_blpairs_from_bls(uvp, bls, only_pairs_in_bls=False):
    """
    Get baseline pair matches from a list of baseline antenna-pairs in a UVPSpec object.

    Parameters
    ----------
    uvp : UVPSpec object with at least meta-data in required params loaded in.
        If only meta-data is loaded in then h5file must be specified.

    bls : list of i6 baseline integers or baseline tuples, Ex. (2, 3) 
        Select all baseline-pairs whose first _or_ second baseline are in bls list.
        This changes if only_pairs_in_bls == True.

    only_pairs_in_bls : bool, if True, keep only baseline-pairs whose first _and_ second baseline
        are both found in bls list.

    Returns blp_select
    -------
    blp_select : boolean ndarray used to index into uvp.blpair_array to get relevant baseline-pairs
    """
    # get blpair baselines in integer form
    bl1 = np.floor(uvp.blpair_array / 1e6)
    blpair_bls = np.vstack([bl1, uvp.blpair_array - bl1*1e6]).astype(np.int).T
    # ensure bls is in integer form
    if isinstance(bls, tuple):
        assert isinstance(bls[0], (int, np.int)), "bls must be fed as a list of baseline tuples Ex: [(1, 2), ...]"
        bls = [uvp.antnums_to_bl(bls)]
    elif isinstance(bls, list):
        if isinstance(bls[0], tuple):
            bls = map(lambda b: uvp.antnums_to_bl(b), bls)
    elif isinstance(bls, (int, np.int)):
        bls = [bls]
    # get indices
    if only_pairs_in_bls:
        blp_select = np.array(map(lambda blp: np.bool((blp[0] in bls) * (blp[1] in bls)), blpair_bls))
    else:
        blp_select = np.array(map(lambda blp: np.bool((blp[0] in bls) + (blp[1] in bls)), blpair_bls))

    return blp_select


def _select(uvp, spws=None, bls=None, only_pairs_in_bls=False, blpairs=None, times=None, pols=None, h5file=None):

    """
    Select function for selecting out certain slices of the data, as well as loading in data from HDF5 file.

    Parameters
    ----------
    uvp : UVPSpec object with at least meta-data in required params loaded in.
        If only meta-data is loaded in then h5file must be specified.

    spws : list of spectral window integers to select

    bls : list of i6 baseline integers or baseline tuples, Ex. (2, 3) 
        Select all baseline-pairs whose first _or_ second baseline are in bls list.
        This changes if only_pairs_in_bls == True.

    only_pairs_in_bls : bool, if True, keep only baseline-pairs whose first _and_ second baseline
        are both found in bls list.

    blpairs : list of baseline-pair tuples or integers to keep, if bls is also fed, this list is concatenated
        onto the baseline-pair list constructed from from the bls selection
    
    times : float ndarray of times from the time_avg_array to keep

    pols : list of polarization strings or integers to keep. See pyuvdata.utils.polstr2num for acceptable options.

    h5file : h5py file descriptor, used for loading in selection of data from HDF5 file
    """
    if spws is not None:
        # spectral window selection
        spw_select = uvp.spw_to_indices(spws)
        uvp.spw_array = uvp.spw_array[spw_select]
        uvp.freq_array = uvp.freq_array[spw_select]
        uvp.dly_array = uvp.dly_array[spw_select]
        uvp.Nspws = len(np.unique(uvp.spw_array))
        uvp.Ndlys = len(np.unique(uvp.dly_array))
        uvp.Nspwdlys = len(uvp.spw_array)
        if hasattr(uvp, 'scalar_array'):
            uvp.scalar_array = uvp.scalar_array[spws, :]

    if bls is not None:
        # get blpair baselines in integer form
        bl1 = np.floor(uvp.blpair_array / 1e6)
        blpair_bls = np.vstack([bl1, uvp.blpair_array - bl1*1e6]).astype(np.int).T
        blp_select = _get_blpairs_from_bls(uvp, bls, only_pairs_in_bls=only_pairs_in_bls)

    if blpairs is not None:
        if bls is None:
            blp_select = np.zeros(uvp.Nblpairts, np.bool)
        # assert form
        assert isinstance(blpairs[0], (tuple, int, np.int)), "blpairs must be fed as a list of baseline-pair tuples or baseline-pair integers"
        # if fed as list of tuples, convert to integers
        if isinstance(blpairs[0], tuple):
            blpairs = map(lambda blp: uvp.antnums_to_blpair(blp), blpairs)
        blpair_select = np.array(reduce(operator.add, map(lambda blp: uvp.blpair_array == blp, blpairs)))
        blp_select += blpair_select

    if times is not None:
        if bls is None and blpairs is None:
            blp_select = np.ones(uvp.Nblpairts, np.bool)
        time_select = np.array(reduce(operator.add, map(lambda t: np.isclose(uvp.time_avg_array, t, rtol=1e-16), times)))
        blp_select *= time_select

    if bls is None and blpairs is None and times is None:
        blp_select = slice(None)
    else:
        # assert something was selected
        assert blp_select.any(), "no selections provided matched any of the data... "

        # index arrays
        uvp.blpair_array = uvp.blpair_array[blp_select]
        uvp.time_1_array = uvp.time_1_array[blp_select]
        uvp.time_2_array = uvp.time_2_array[blp_select]
        uvp.time_avg_array = uvp.time_avg_array[blp_select]
        uvp.lst_1_array = uvp.lst_1_array[blp_select]
        uvp.lst_2_array = uvp.lst_2_array[blp_select]
        uvp.lst_avg_array = uvp.lst_avg_array[blp_select]
        uvp.Ntimes = len(np.unique(uvp.time_avg_array))
        uvp.Nblpairs = len(np.unique(uvp.blpair_array))
        uvp.Nblpairts = len(uvp.blpair_array)
        if bls is not None:
            bl_array = np.unique(blpair_bls)
            bl_select = reduce(operator.add, map(lambda b: uvp.bl_array==b, bl_array))
            uvp.bl_array = uvp.bl_array[bl_select]
            uvp.bl_vecs = uvp.bl_vecs[bl_select]
            uvp.Nbls = len(uvp.bl_array)        

    if pols is not None:
        # assert form
        assert isinstance(pols[0], (str, np.str, int, np.int)), "pols must be fed as a list of pol strings or pol integers"

        # if fed as strings convert to integers
        if isinstance(pols[0], (np.str, str)):
            pols = map(lambda p: uvutils.polstr2num(p), pols)

        # create selection
        pol_select = np.array(reduce(operator.add, map(lambda p: uvp.pol_array == p, pols)))

        # edit metadata
        uvp.pol_array = uvp.pol_array[pol_select]
        uvp.Npols = len(uvp.pol_array)
        if hasattr(uvp, 'scalar_array'):
            uvp.scalar_array = uvp.scalar_array[:, pol_select]
    else:
        pol_select = slice(None)

    try:
        # select data arrays
        data = odict()
        wgts = odict()
        ints = odict()
        nsmp = odict()
        for s in np.unique(uvp.spw_array):
            if h5file is not None:
                data[s] = h5file['data_spw{}'.format(s)][blp_select, :, pol_select]
                wgts[s] = h5file['wgt_spw{}'.format(s)][blp_select, :, :, pol_select]
                ints[s] = h5file['integration_spw{}'.format(s)][blp_select, pol_select]
                nsmp[s] = h5file['nsample_spw{}'.format(s)][blp_select, pol_select]
            else:
                data[s] = uvp.data_array[s][blp_select, :, pol_select]
                wgts[s] = uvp.wgt_array[s][blp_select, :, :, pol_select]
                ints[s] = uvp.integration_array[s][blp_select, pol_select]
                nsmp[s] = uvp.nsample_array[s][blp_select, pol_select]
 
        uvp.data_array = data
        uvp.wgt_array = wgts
        uvp.integration_array = ints
        uvp.nsample_array = nsmp
    except AttributeError:
        # if no h5file fed and hasattr(uvp, data_array) is False then just load meta-data
        pass




def _blpair_to_antnums(blpair):
    """
    Convert baseline-pair integer to nested tuple of antenna numbers.

    Parameters
    ----------
    blpair : <i12 integer
        baseline-pair integer

    Return
    ------
    antnums : tuple
        nested tuple containing baseline-pair antenna numbers. Ex. ((ant1, ant2), (ant3, ant4))
    """
    # get antennas
    ant1 = int(np.floor(blpair / 1e9))
    ant2 = int(np.floor(blpair / 1e6 - ant1*1e3))
    ant3 = int(np.floor(blpair / 1e3 - ant1*1e6 - ant2*1e3))
    ant4 = int(np.floor(blpair - ant1*1e9 - ant2*1e6 - ant3*1e3))

    # form antnums tuple
    antnums = ((ant1, ant2), (ant3, ant4))

    return antnums

def _antnums_to_blpair(antnums):
    """
    Convert nested tuple of antenna numbers to baseline-pair integer.

    Parameters
    ----------
    antnums : tuple
        nested tuple containing integer antenna numbers for a baseline-pair.
        Ex. ((ant1, ant2), (ant3, ant4))

    Return
    ------
    blpair : <i12 integer
        baseline-pair integer
    """
    # get antennas
    ant1 = antnums[0][0]
    ant2 = antnums[0][1]
    ant3 = antnums[1][0]
    ant4 = antnums[1][1]

    # form blpair
    blpair = int(ant1*1e9 + ant2*1e6 + ant3*1e3 + ant4)

    return blpair

def _bl_to_antnums(bl):
    """
    Convert baseline integer to tuple of antenna numbers.

    Parameters
    ----------
    blpair : <i6 integer
        baseline integer

    Return
    ------
    antnums : tuple
        tuple containing baseline antenna numbers. Ex. (ant1, ant2)
    """
    # get antennas
    ant1 = int(np.floor(bl / 1e3))
    ant2 = int(np.floor(bl - ant1*1e3))

    # form antnums tuple
    antnums = (ant1, ant2)

    return antnums

def _antnums_to_bl(antnums):
    """
    Convert tuple of antenna numbers to baseline integer.

    Parameters
    ----------
    antnums : tuple
        tuple containing integer antenna numbers for a baseline.
        Ex. (ant1, ant2)

    Return
    ------
    blpair : <i6 integer
        baseline integer
    """
    # get antennas
    ant1 = antnums[0]
    ant2 = antnums[1]

    # form blpair
    blpair = int(ant1*1e3 + ant2)

    return blpair

def _blpair_to_bls(blpair):
    """
    Convert a blpair integer or nested tuple of antenna pairs
    into a tuple of baseline integers

    Parameters
    ----------
    blpair : baseline-pair integer or nested antenna-pair tuples
    """
    # convert to antnums if fed as ints
    if isinstance(blpair, (int, np.int)):
        blpair = _blpair_to_antnums(blpair)

    # convert first and second baselines to baseline ints
    bl1 = _antnums_to_bl(blpair[0])
    bl2 = _antnums_to_bl(blpair[1])

    return bl1, bl2

def _conj_blpair_int(blpair):
    """
    Conjugate a baseline-pair integer

    Parameters
    ----------
    blpair : <12 int
        baseline-pair integer

    Return
    -------
    conj_blpair : <12 int
        conjugated baseline-pair integer. 
        Ex: ((ant1, ant2), (ant3, ant4)) --> ((ant3, ant4), (ant1, ant2))
    """
    antnums = _blpair_to_antnums(blpair)
    conj_blpair = _antnums_to_blpair(antnums[::-1])
    return conj_blpair


def _conj_bl_int(bl):
    """
    Conjugate a baseline integer

    Parameters
    ----------
    blpair : i6 int
        baseline integer

    Return
    -------
    conj_bl : i6 int
        conjugated baseline integer. 
        Ex: (ant1, ant2) --> (ant2, ant1)
    """
    antnums = _bl_to_antnums(bl)
    conj_bl = _antnums_to_bl(antnums[::-1])
    return conj_bl


def _conj_blpair(blpair, which='both'):
    """
    Conjugate one or both baseline(s) in a baseline-pair
    Ex. ((ant1, ant2), (ant3, ant4)) --> ((ant2, ant1), (ant4, ant3))

    Parameters
    ----------
    blpair : <12 int
        baseline-pair int

    which : str, options=['first', 'second', 'both']
        which baseline to conjugate

    Return
    ------
    conj_blpair : <12 int
        blpair with one or both baselines conjugated
    """
    antnums = _blpair_to_antnums(blpair)
    if which == 'first':
        conj_blpair = _antnums_to_blpair((antnums[0][::-1], antnums[1]))
    elif which == 'second':
        conj_blpair = _antnums_to_blpair((antnums[0], antnums[1][::-1]))
    elif which == 'both':
        conj_blpair = _antnums_to_blpair((antnums[0][::-1], antnums[1][::-1]))
    else:
        raise ValueError("didn't recognize {}".format(which))

    return conj_blpair


